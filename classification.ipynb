{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from langdetect import detect\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rev 1 -> hrs  \n",
    "rev2 -> hotelsone  \n",
    "rev 3 -> galahotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hrs = pd.read_csv('./scrapped_reviews/trustpilot_reviews_1.csv')\n",
    "df_sone = pd.read_csv('./scrapped_reviews/trustpilot_reviews_2.csv')\n",
    "df_gala = pd.read_csv('./scrapped_reviews/trustpilot_reviews_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A great finding</td>\n",
       "      <td>Not so much known like other OTAs but really w...</td>\n",
       "      <td>Date of experience: December 17, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good choice!</td>\n",
       "      <td>Easy booking process, wide selection of hotels...</td>\n",
       "      <td>Date of experience: December 16, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Its a really good site when you need to…</td>\n",
       "      <td>Its a really good site when you need to book s...</td>\n",
       "      <td>Date of experience: December 16, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This was a great hotel</td>\n",
       "      <td>This was a great hotel. very comfortable and p...</td>\n",
       "      <td>Date of experience: November 18, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friendly staff</td>\n",
       "      <td>Friendly staff, good location, clean and spaci...</td>\n",
       "      <td>Date of experience: December 11, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Best Rate</td>\n",
       "      <td>I made a booking at a Barcelona hotel using Bo...</td>\n",
       "      <td>Date of experience: June 23, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>special offers</td>\n",
       "      <td>This site has often special offers for high qu...</td>\n",
       "      <td>Date of experience: October 14, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>latest arrival time/reception hours…</td>\n",
       "      <td>on HRS there is seldom information on the late...</td>\n",
       "      <td>Date of experience: July 15, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>I am very satisfied you can improve…</td>\n",
       "      <td>I am very satisfied you can improve your web p...</td>\n",
       "      <td>Date of experience: September 04, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>HrS was available to show their…</td>\n",
       "      <td>HrS was available to show their discount.  by ...</td>\n",
       "      <td>Date of experience: September 28, 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0                              A great finding   \n",
       "1                                 Good choice!   \n",
       "2     Its a really good site when you need to…   \n",
       "3                       This was a great hotel   \n",
       "4                               Friendly staff   \n",
       "...                                        ...   \n",
       "4995                                 Best Rate   \n",
       "4996                            special offers   \n",
       "4997      latest arrival time/reception hours…   \n",
       "4998      I am very satisfied you can improve…   \n",
       "4999          HrS was available to show their…   \n",
       "\n",
       "                                                   body  \\\n",
       "0     Not so much known like other OTAs but really w...   \n",
       "1     Easy booking process, wide selection of hotels...   \n",
       "2     Its a really good site when you need to book s...   \n",
       "3     This was a great hotel. very comfortable and p...   \n",
       "4     Friendly staff, good location, clean and spaci...   \n",
       "...                                                 ...   \n",
       "4995  I made a booking at a Barcelona hotel using Bo...   \n",
       "4996  This site has often special offers for high qu...   \n",
       "4997  on HRS there is seldom information on the late...   \n",
       "4998  I am very satisfied you can improve your web p...   \n",
       "4999  HrS was available to show their discount.  by ...   \n",
       "\n",
       "                                        date  \n",
       "0      Date of experience: December 17, 2024  \n",
       "1      Date of experience: December 16, 2024  \n",
       "2      Date of experience: December 16, 2024  \n",
       "3      Date of experience: November 18, 2024  \n",
       "4      Date of experience: December 11, 2024  \n",
       "...                                      ...  \n",
       "4995       Date of experience: June 23, 2024  \n",
       "4996    Date of experience: October 14, 2024  \n",
       "4997       Date of experience: July 15, 2024  \n",
       "4998  Date of experience: September 04, 2024  \n",
       "4999  Date of experience: September 28, 2024  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "body     0\n",
       "date     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 missing value in titlt col in df_gala\n",
    "df_gala['title'] = df_gala['title'].fillna('No Title')\n",
    "df_gala.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Traduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thiba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#------Function for removing english stopwords------#\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "def remove_stopwords(text, lang='english'):\n",
    "    stop_words = set(stopwords.words(lang))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------Function for translating to english------#\n",
    "\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_avis(avis, lang):\n",
    "    return GoogleTranslator(source=lang, target='en').translate(avis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "sym_spell.load_dictionary(\"./frequency_dictionary_en_82_765.txt\", term_index=0, count_index=1)\n",
    "\n",
    "def correct_spelling_fast(text, lang='en'):\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    corrected_words = []\n",
    "    for word in words:\n",
    "        correction = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "        corrected_words.append(correction[0].term if correction else word)\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HRS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hrs['body'] = df_hrs['body'].str.lower()\n",
    "df_hrs['body'] = df_hrs['body'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df_hrs['body'] = df_hrs['body'].apply(lambda x: emoji.replace_emoji(x, replace=''))\n",
    "df_hrs['language'] = df_hrs['body'].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hrs['language'].unique() #only english no need to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hrs['body'] = df_hrs['body'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hrs['body'] = df_hrs['body'].apply(lambda x: correct_spelling_fast(x, lang='en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hrs.to_csv('./cleaned_rev/hrs_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hotelsone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sone['body'] = df_sone['body'].str.lower()\n",
    "df_sone['body'] = df_sone['body'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df_sone['body'] = df_sone['body'].apply(lambda x: emoji.replace_emoji(x, replace=''))\n",
    "df_sone = df_sone[df_sone['body'].str.strip().astype(bool)] # remove reviews that only contains whitespaces\n",
    "df_sone['language'] = df_sone['body'].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'da', 'fr', 'sk', 'fi', 'af', 'tl', 'so', 'it', 'cs', 'pl',\n",
       "       'ro', 'es', 'cy', 'pt', 'no', 'nl', 'ca', 'lv', 'sl'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sone['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "en    3798\n",
      "sk    1086\n",
      "fr      32\n",
      "af      12\n",
      "ro      12\n",
      "da      11\n",
      "tl      10\n",
      "it       8\n",
      "ca       6\n",
      "es       6\n",
      "so       4\n",
      "cy       2\n",
      "pt       2\n",
      "sl       2\n",
      "cs       2\n",
      "fi       2\n",
      "no       1\n",
      "nl       1\n",
      "lv       1\n",
      "pl       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_sone['language'].value_counts()) #Many reviews in other languages, need to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sone = df_sone[df_sone['language'] == 'en'] #Garder uniquement les review en anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sone['body'] = df_sone['body'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sone['body'] = df_sone['body'].apply(lambda x: correct_spelling_fast(x, lang='en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sone.to_csv('./cleaned_rev/HotelSone_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gala Hotel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gala['body'] = df_gala['body'].str.lower()\n",
    "df_gala['body'] = df_gala['body'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df_gala['body'] = df_gala['body'].apply(lambda x: emoji.replace_emoji(x, replace=''))\n",
    "df_gala = df_gala[df_gala['body'].str.strip().astype(bool)] # remove reviews that only contains whitespaces\n",
    "df_gala['language'] = df_gala['body'].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'sk', 'sl', 'it', 'es', 'af', 'ca', 'fr', 'da', 'pl', 'so',\n",
       "       'de', 'nl', 'ro', 'cy', 'hr', 'pt', 'no', 'tl'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gala['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gala = df_gala[df_gala['language'] == 'en'] #Garder uniquement les review en anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gala['body'] = df_gala['body'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gala['body'] = df_gala['body'].apply(lambda x: correct_spelling_fast(x, lang='en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gala.to_csv('./cleaned_rev/GalaHotel_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_hrs, df_sone, df_gala], ignore_index=True)\n",
    "df_combined.to_csv('./cleaned_rev/concat_rev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Classification (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(df_combined['body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "friendly, good, staff, clean, location, great, room, spacious, excellent, live, helpful, nice, stay, service, offers, hotel, site, comfortable, best, sure\n",
      "Topic 1:\n",
      "valid, easily, card, book, using, credit, hotel, hrs, rates, issues, reliable, search, point, willing, able, rating, shows, course, consistently, end\n",
      "Topic 2:\n",
      "hotel, room, booking, best, prices, hrs, breakfast, avoid, process, easy, night, use, good, old, bad, included, nice, staff, desk, clean\n",
      "Topic 3:\n",
      "really, good, business, site, pricing, rooms, wants, need, platform, limited, past, recently, people, significant, perfect, number, wonderful, experience, book, options\n",
      "Topic 4:\n",
      "easy, simple, fast, rates, hotels, use, booking, process, choice, convenient, selection, bookings, particular, germany, interesting, la, reward, wide, cities, small\n",
      "Topic 5:\n",
      "improve, information, site, hotels, user, hrs, satisfied, quality, high, friendliness, bit, web, worth, automatically, regards, italian, blast, kind, applied, page\n",
      "Topic 6:\n",
      "hotel, easy, booking, quick, website, reservation, gala, half, price, booked, confirmation, refund, book, stay, room, problem, company, recommended, use, available\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "n_topics = 7\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "\n",
    "lda.fit(X_tfidf)\n",
    "\n",
    "# Extract the topics (words associated with each topic)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "n_top_words = 20  # Number of words to display per topic\n",
    "\n",
    "# Print topics\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {topic_idx}:\")\n",
    "    print(\", \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not satisfying enough, We will try using zero-shot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic distribution for each review\n",
    "topic_distribution = lda.transform(X_tfidf)\n",
    "\n",
    "# Assign the review to the topic with the highest probability\n",
    "df_combined['assigned_topic'] = topic_distribution.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        4\n",
       "2        3\n",
       "3        3\n",
       "4        0\n",
       "        ..\n",
       "13343    3\n",
       "13344    0\n",
       "13345    0\n",
       "13346    6\n",
       "13347    0\n",
       "Name: assigned_topic, Length: 13348, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['assigned_topic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic classification (Zero-shot Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Reviews: 100%|██████████| 13348/13348 [26:41<00:00,  8.34review/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                body classif_result\n",
      "0  much known like otis really worth book rooms w...          value\n",
      "1  easy booking process wide selection hotels eve...          rooms\n",
      "2  really good site need book several rooms wants...          rooms\n",
      "3  great hotel comfortable perfect short staysthe...          rooms\n",
      "4   friendly staff good location clean spacious room    cleanliness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "labels = ['service', 'cleanliness', 'overall', 'value', 'location', 'sleep_quality', 'rooms']\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"knowledgator/comprehend_it-base\", device=0)\n",
    "result = []\n",
    "dataset = Dataset.from_pandas(df_combined[['body']])\n",
    "for review in tqdm(dataset['body'], total=len(dataset['body']), desc=\"Classifying Reviews\", unit=\"review\"):\n",
    "    classification = classifier(review, candidate_labels=labels)\n",
    "    top_label = classification['labels'][0]\n",
    "    result.append(top_label)\n",
    "df_combined['classif_result'] = result\n",
    "\n",
    "# Check the updated DataFrame\n",
    "print(df_combined[['body', 'classif_result']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('./nlp_results/rev_topic.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Classifying Reviews: 100%|██████████| 13348/13348 [11:12<00:00, 19.86review/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                body sentiment_result\n",
      "0  much known like otis really worth book rooms w...         Positive\n",
      "1  easy booking process wide selection hotels eve...         Positive\n",
      "2  really good site need book several rooms wants...         Positive\n",
      "3  great hotel comfortable perfect short staysthe...         Positive\n",
      "4   friendly staff good location clean spacious room         Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "labels_st = ['Positive', 'Negative', 'Neutral']\n",
    "classifier_st = pipeline(\"zero-shot-classification\", model=\"FacebookAI/roberta-base\", device=0)\n",
    "result_st = []\n",
    "for review in tqdm(dataset['body'], total=len(dataset['body']), desc=\"Classifying Reviews\", unit=\"review\"):\n",
    "    classification = classifier(review, candidate_labels=labels_st)\n",
    "    top_label = classification['labels'][0]\n",
    "    result_st.append(top_label)\n",
    "df_combined['sentiment_result'] = result_st\n",
    "\n",
    "print(df_combined[['body', 'sentiment_result']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('./nlp_results/rev_topic_sentiment.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
